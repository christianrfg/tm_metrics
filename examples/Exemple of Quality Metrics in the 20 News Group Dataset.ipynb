{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show how to use the tm_metrics library for extract the quality metrics propose by [Topic Quality Metrics Based on Distributed Word\n",
    "Representations](https://logic.pdmi.ras.ru/~sergey/papers/N16_SIGIR.pdf).\n",
    "\n",
    "For show the usage of the tm_metrics library, we use the example show by [Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation](https://scikit-learn.org/0.20/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py) with a few modifications. For the topics generated by the NMF algorithm, we show the summary of each metrics provided by the library (i.e., Coherence, TFIDF-Coherence, LCP, PMI, NMPI and measures based on Word Embedding).\n",
    "\n",
    "**Attention:** Although we use the NMF algorithm for topic modelling, we can use any algorithm for calculate the quality metrics. All what we need is the words per topic and the raw documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:42:40.899190Z",
     "start_time": "2020-01-23T18:42:40.691909Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from tm_metrics.feature_extraction import get_tfidf_matrices, get_vocabulary, get_word_frequencies\n",
    "from tm_metrics.metrics import coherence, tfidf_coherence, lcp, pmi, topic_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:42:23.591375Z",
     "start_time": "2020-01-23T18:42:23.588990Z"
    }
   },
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_components = 10\n",
    "n_top_words = 20\n",
    "seed = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:42:23.603535Z",
     "start_time": "2020-01-23T18:42:23.593130Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_topics(model, feature_names, n_top_words):\n",
    "    topics = []\n",
    "\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        topics.append(topic)\n",
    "\n",
    "    return topics\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = f\"Topic #{topic_idx}: \"\n",
    "        message += \" \".join(\n",
    "            [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling with TF-IDF e NMF for the 20 News Group Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading 20 News Group Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:42:24.715737Z",
     "start_time": "2020-01-23T18:42:23.605062Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=seed,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "data_samples = dataset.data[:n_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple word embedding from gensim (necessary in W2V Metrics):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:42:46.507234Z",
     "start_time": "2020-01-23T18:42:43.804336Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_data_samples = [str.split(x) for x in data_samples]\n",
    "model = Word2Vec(w2v_data_samples, size=100, window=5, min_count=1, workers=4)\n",
    "word_embedding = model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF Representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:42:49.473092Z",
     "start_time": "2020-01-23T18:42:49.204493Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=n_features, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF for topic modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:42:49.895050Z",
     "start_time": "2020-01-23T18:42:49.474705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.1, beta_loss='frobenius', init=None, l1_ratio=0.5, max_iter=200,\n",
       "  n_components=10, random_state=1, shuffle=False, solver='cd', tol=0.0001,\n",
       "  verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf = NMF(n_components=n_components, random_state=1, alpha=.1, l1_ratio=.5)\n",
    "nmf.fit(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics generated by the NMF algorithm using the TF-IDF representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:42:49.910527Z",
     "start_time": "2020-01-23T18:42:49.905982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: just like don people think know good time ve right say way make did really does want ll going use\n",
      "Topic #1: windows files use dos file program version ftp ms 00 application directory using hi pc window used image printer drivers\n",
      "Topic #2: game team games hockey play year league win players season teams player best runs think points star fan good night\n",
      "Topic #3: god jesus faith christian man christ sin christians father church life believe son lord bible religion truth christianity belief word\n",
      "Topic #4: drive scsi disk drives hard floppy ide mb computer controller tape sale cd dos pay bus format speed power local\n",
      "Topic #5: com list request mailing send hp sun edu article email ibm address voice internet want file wish user ask games\n",
      "Topic #6: thanks advance address know looking does mail hi info send anybody help interested appreciate information email appreciated software like work\n",
      "Topic #7: key chip clipper encryption keys government escrow security privacy public use algorithm des chips phone nsa administration technology enforcement data\n",
      "Topic #8: new car price miles trial used condition excellent try bought box old included year sale gm thinking model asking talking\n",
      "Topic #9: card video monitor problem color cards vga apple mode bus memory drivers driver mouse modem support switch display hardware mac\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "topics = get_topics(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Quality Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each topic generated by the NMF algorithm in the last step, we calculate the metrics provided by tm_metrics library. We show the **mean** and **standard deviation** of each metric implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we've to get the informations from the dataset documents. **We chose to use the calculation of these informations before the metrics executions for improve efficience**. Otherwiser, we need to calculate each information in each metric. By doing this step we need to do this just once, reutilizing the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:43:21.514536Z",
     "start_time": "2020-01-23T18:42:49.912022Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_matrix, tfidf_matrix_transpose = get_tfidf_matrices(data_samples)\n",
    "vocabulary = get_vocabulary(data_samples)\n",
    "word_frequency, word_frequency_in_documents = get_word_frequencies(data_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of all quality metrics for the topics we generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:46:16.130610Z",
     "start_time": "2020-01-23T18:45:08.784855Z"
    }
   },
   "outputs": [],
   "source": [
    "pmi_results = []\n",
    "npmi_results = []\n",
    "coherence_results = []\n",
    "tfidf_coherence_results = []\n",
    "lcp_results = []\n",
    "w2v_l2_results = []\n",
    "\n",
    "for topic_words in topics:\n",
    "    pmi_ = pmi(topic_words, word_frequency, word_frequency_in_documents, n_samples, normalise=False)\n",
    "    npmi_ = pmi(topic_words, word_frequency, word_frequency_in_documents, n_samples, normalise=True)\n",
    "    coherence_ = coherence(topic_words, word_frequency, word_frequency_in_documents)\n",
    "    tfidf_coherence_ = tfidf_coherence(topic_words, tfidf_matrix_transpose, vocabulary)\n",
    "    lcp_ = lcp(topic_words, word_frequency, word_frequency_in_documents)\n",
    "    w2v_l2_ = topic_w2v(topic_words, word_embedding)\n",
    "    \n",
    "    pmi_results.append(pmi_)\n",
    "    npmi_results.append(npmi_)\n",
    "    coherence_results.append(coherence_)\n",
    "    tfidf_coherence_results.append(tfidf_coherence_)\n",
    "    lcp_results.append(lcp_)\n",
    "    w2v_l2_results.append(w2v_l2_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obs.: we use just the L2 Distance of Word Embeddings metrics, but we have the 4 implementations proposed in the paper.\n",
    "\n",
    "Now we've all the quality metrics for each topic, where all the topics are generated with the TF-IDF representation and the NMF algorithm.\n",
    "\n",
    "Next we can see the average and standard deviation of each metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:46:33.704274Z",
     "start_time": "2020-01-23T18:46:33.685634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Avg</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PMI</td>\n",
       "      <td>303.014431</td>\n",
       "      <td>101.428537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NPMI</td>\n",
       "      <td>0.285646</td>\n",
       "      <td>0.085899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coherence</td>\n",
       "      <td>-156.715721</td>\n",
       "      <td>23.784665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TFIDF_Coherence</td>\n",
       "      <td>-131.323619</td>\n",
       "      <td>30.578120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LCP</td>\n",
       "      <td>-375.271750</td>\n",
       "      <td>49.228210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>W2V-L2-Distance</td>\n",
       "      <td>3.098983</td>\n",
       "      <td>3.406839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Metric         Avg         Std\n",
       "0              PMI  303.014431  101.428537\n",
       "1             NPMI    0.285646    0.085899\n",
       "2        Coherence -156.715721   23.784665\n",
       "3  TFIDF_Coherence -131.323619   30.578120\n",
       "4              LCP -375.271750   49.228210\n",
       "5  W2V-L2-Distance    3.098983    3.406839"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pmi, std_pmi = np.mean(pmi_results), np.std(pmi_results)\n",
    "avg_npmi, std_npmi = np.mean(npmi_results), np.std(npmi_results)\n",
    "avg_coherence, std_coherence = np.mean(coherence_results), np.std(coherence_results)\n",
    "avg_tfidf, std_tfidf = np.mean(tfidf_coherence_results), np.std(tfidf_coherence_results)\n",
    "avg_lcp, std_lcp = np.mean(lcp_results), np.std(lcp_results)\n",
    "avg_l2, std_l2 = np.mean(w2v_l2_results), np.std(w2v_l2_results)\n",
    "\n",
    "data = [\n",
    "    [\"PMI\", avg_pmi, std_pmi],\n",
    "    [\"NPMI\", avg_npmi, std_npmi],\n",
    "    [\"Coherence\", avg_coherence, std_coherence],\n",
    "    [\"TFIDF_Coherence\", avg_tfidf, std_tfidf],\n",
    "    [\"LCP\", avg_lcp, std_lcp],\n",
    "    [\"W2V-L2-Distance\", avg_l2, std_l2]\n",
    "]\n",
    "columns = [\"Metric\", \"Avg\", \"Std\"]\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
